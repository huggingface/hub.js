/** This file is auto-generated by generate-llm.ts */

import type { ModelBase, GGUFGeneralInfo } from "./types";

type LLMBase<TArchitecture extends string> = Partial<
	Record<
		`${TArchitecture}.vocab_size` | `${TArchitecture}.use_parallel_residual` | `${TArchitecture}.tensor_data_layout`,
		number
	>
>;

type Attention<TArchitecture extends string> = Record<`${TArchitecture}.attention.head_count`, number> &
	Partial<
		Record<
			| `${TArchitecture}.attention.head_count_kv`
			| `${TArchitecture}.attention.key_length`
			| `${TArchitecture}.attention.value_length`,
			number
		>
	>;

export type TransformerLLMRopeScalingType = "none" | "linear" | "yarn";
type Rope<TArchitecture extends LLMArchitecture> = Partial<
	Record<
		| `${TArchitecture}.rope.dimension_count`
		| `${TArchitecture}.rope.freq_base`
		| `${TArchitecture}.rope.scale_linear`
		| `${TArchitecture}.rope.scaling.factor`
		| `${TArchitecture}.rope.scaling.original_context_length`,
		number
	> &
		Record<`${TArchitecture}.rope.scaling.type`, TransformerLLMRopeScalingType> &
		Record<`${TArchitecture}.rope.finetuned`, boolean>
>;

type MOE<TArchitecture extends LLMArchitecture> = Partial<
	Record<`${TArchitecture}.expert_count` | `${TArchitecture}.expert_used_count`, number>
>;

export type TransformerLLMArchitecture = LLMArchitecture; // type alias
export type TransformerLLMBase<TArchitecture extends LLMArchitecture> = GGUFGeneralInfo<TArchitecture> &
	LLMBase<TArchitecture> &
	ModelBase<TArchitecture> &
	MOE<TArchitecture> &
	Attention<TArchitecture> &
	Rope<TArchitecture>;

export enum TransformerLLMPoolingType {
	UNSPECIFIED = -1,
	NONE = 0,
	MEAN = 1,
	CLS = 2,
}

export const LLM_ARCHITECTURES = [
	"llama",
	"falcon",
	"grok",
	"gpt2",
	"gptj",
	"gptneox",
	"mpt",
	"baichuan",
	"starcoder",
	"persimmon",
	"refact",
	"bert",
	"nomic-bert",
	"bloom",
	"stablelm",
	"qwen",
	"qwen2",
	"qwen2moe",
	"phi2",
	"phi3",
	"plamo",
	"codeshell",
	"orion",
	"internlm2",
	"minicpm",
	"gemma",
	"starcoder2",
	"mamba",
	"xverse",
	"command-r",
	"dbrx",
	"olmo",
] as const;
type LLMArchitecture = (typeof LLM_ARCHITECTURES)[number];
export type ArchLlama = TransformerLLMBase<"llama"> & {
	"llama.attention.layer_norm_rms_epsilon": number;
};
export type ArchFalcon = TransformerLLMBase<"falcon"> & {
	"falcon.attention.layer_norm_epsilon": number;
};
export type ArchGrok = TransformerLLMBase<"grok"> & {
	"grok.attention.layer_norm_rms_epsilon": number;
};
export type ArchGpt2 = TransformerLLMBase<"gpt2"> & {
	"gpt2.attention.layer_norm_epsilon": number;
};
export type ArchGptj = TransformerLLMBase<"gptj">;
export type ArchGptneox = TransformerLLMBase<"gptneox">;
export type ArchMpt = TransformerLLMBase<"mpt"> & {
	"mpt.attention.layer_norm_epsilon": number;
	"mpt.attention.clamp_kqv": number;
	"mpt.attention.max_alibi_bias": number;
};
export type ArchBaichuan = TransformerLLMBase<"baichuan"> & {
	"baichuan.attention.layer_norm_rms_epsilon": number;
};
export type ArchStarcoder = TransformerLLMBase<"starcoder"> & {
	"starcoder.attention.layer_norm_epsilon": number;
};
export type ArchPersimmon = TransformerLLMBase<"persimmon"> & {
	"persimmon.attention.layer_norm_epsilon": number;
};
export type ArchRefact = TransformerLLMBase<"refact"> & {
	"refact.attention.layer_norm_rms_epsilon": number;
};
export type ArchBert = TransformerLLMBase<"bert"> & {
	"bert.attention.layer_norm_epsilon": number;
	"bert.attention.causal": boolean;
	"tokenizer.ggml.token_type_count": number;
	"bert.pooling_type": TransformerLLMPoolingType;
};
export type ArchNomicBert = TransformerLLMBase<"nomic-bert"> & {
	"nomic-bert.attention.layer_norm_epsilon": number;
	"nomic-bert.attention.causal": boolean;
	"tokenizer.ggml.token_type_count": number;
	"nomic-bert.pooling_type": TransformerLLMPoolingType;
};
export type ArchBloom = TransformerLLMBase<"bloom"> & {
	"bloom.attention.layer_norm_epsilon": number;
};
export type ArchStablelm = TransformerLLMBase<"stablelm"> & {
	"stablelm.attention.layer_norm_epsilon": number;
};
export type ArchQwen = TransformerLLMBase<"qwen"> & {
	"qwen.attention.layer_norm_rms_epsilon": number;
};
export type ArchQwen2 = TransformerLLMBase<"qwen2"> & {
	"qwen2.attention.layer_norm_rms_epsilon": number;
};
export type ArchQwen2moe = TransformerLLMBase<"qwen2moe"> & {
	"qwen2moe.attention.layer_norm_rms_epsilon": number;
};
export type ArchPhi2 = TransformerLLMBase<"phi2"> & {
	"phi2.attention.layer_norm_epsilon": number;
};
export type ArchPhi3 = TransformerLLMBase<"phi3"> & {
	"phi3.attention.layer_norm_rms_epsilon": number;
};
export type ArchPlamo = TransformerLLMBase<"plamo"> & {
	"plamo.attention.layer_norm_rms_epsilon": number;
};
export type ArchCodeshell = TransformerLLMBase<"codeshell"> & {
	"codeshell.attention.layer_norm_epsilon": number;
};
export type ArchOrion = TransformerLLMBase<"orion"> & {
	"orion.attention.layer_norm_epsilon": number;
};
export type ArchInternlm2 = TransformerLLMBase<"internlm2"> & {
	"internlm2.attention.layer_norm_rms_epsilon": number;
};
export type ArchMinicpm = TransformerLLMBase<"minicpm"> & {
	"minicpm.attention.layer_norm_rms_epsilon": number;
};
export type ArchGemma = TransformerLLMBase<"gemma"> & {
	"gemma.attention.layer_norm_rms_epsilon": number;
};
export type ArchStarcoder2 = TransformerLLMBase<"starcoder2"> & {
	"starcoder2.attention.layer_norm_epsilon": number;
};
export type ArchMamba = TransformerLLMBase<"mamba"> & {
	"mamba.ssm.conv_kernel": number;
	"mamba.ssm.inner_size": number;
	"mamba.ssm.state_size": number;
	"mamba.ssm.time_step_rank": number;
	"mamba.attention.layer_norm_rms_epsilon": number;
};
export type ArchXverse = TransformerLLMBase<"xverse"> & {
	"xverse.attention.layer_norm_rms_epsilon": number;
};
export type ArchCommandR = TransformerLLMBase<"command-r"> & {
	"command-r.logit_scale": number;
	"command-r.attention.layer_norm_epsilon": number;
};
export type ArchDbrx = TransformerLLMBase<"dbrx"> & {
	"dbrx.attention.layer_norm_epsilon": number;
	"dbrx.attention.clamp_kqv": number;
};
export type ArchOlmo = TransformerLLMBase<"olmo"> & {
	"olmo.attention.layer_norm_epsilon": number;
	"olmo.attention.clamp_kqv": number;
};

export type TransformerLLM =
	| ArchLlama
	| ArchFalcon
	| ArchGrok
	| ArchGpt2
	| ArchGptj
	| ArchGptneox
	| ArchMpt
	| ArchBaichuan
	| ArchStarcoder
	| ArchPersimmon
	| ArchRefact
	| ArchBert
	| ArchNomicBert
	| ArchBloom
	| ArchStablelm
	| ArchQwen
	| ArchQwen2
	| ArchQwen2moe
	| ArchPhi2
	| ArchPhi3
	| ArchPlamo
	| ArchCodeshell
	| ArchOrion
	| ArchInternlm2
	| ArchMinicpm
	| ArchGemma
	| ArchStarcoder2
	| ArchMamba
	| ArchXverse
	| ArchCommandR
	| ArchDbrx
	| ArchOlmo;
